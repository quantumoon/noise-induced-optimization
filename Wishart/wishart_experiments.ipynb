{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f774c8d-3548-4ed1-b536-8f102996ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.random as jr\n",
    "import optax\n",
    "import jaxopt\n",
    "from jax import numpy as jnp, jit, vmap, grad\n",
    "from functools import reduce, partial\n",
    "from tqdm import tqdm\n",
    "from wishart_loss import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670fd5e-de0f-4ed9-ac19-d94385522c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_optimize_with_adam(loss_fn, mu_schedule, x_init, num_iterations, learning_rate):\n",
    "    opt = optax.adam(learning_rate)\n",
    "    \n",
    "    @jit\n",
    "    def step(mu, params, opt_state):\n",
    "        grads = grad(partial(loss_fn, mu))(params)\n",
    "        updates, opt_state = opt.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        return params, opt_state\n",
    "\n",
    "    def optimize_single(params):\n",
    "        opt_state = opt.init(params)\n",
    "        for i in range(num_iterations):\n",
    "            mu = mu_schedule(i / num_iterations)\n",
    "            params, opt_state = step(mu, params, opt_state)\n",
    "        return params\n",
    "\n",
    "    final_params = vmap(optimize_single)(x_init)\n",
    "    return final_params\n",
    "\n",
    "\n",
    "def estimated_order(noisy_loss, num_parameters, num_samples=100, mu=0.25):\n",
    "    rng = np.random.default_rng(43)\n",
    "    x = 2*np.pi*rng.uniform(size=(num_samples, num_parameters))\n",
    "    \n",
    "    mu_vals = vmap(partial(noisy_loss, mu))(x)\n",
    "    vals = vmap(partial(noisy_loss, 0.))(x)\n",
    "        \n",
    "    k_est = np.log(mu_vals.std()/vals.std()) / np.log(1-mu)\n",
    "    \n",
    "    return k_est\n",
    "\n",
    "\n",
    "def tanh_schedule(strength: float, max_mu: float, t_stop: float):\n",
    "    def f(t):\n",
    "        return max_mu * max(0, np.tanh(strength * (1 - t / t_stop))) / np.tanh(strength)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb07f0-93e3-4698-8ca3-300649e52c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(dim, ranks, schedules, x,\n",
    "                    num_iterations=4000,\n",
    "                    learning_rate=0.05,\n",
    "                    num_matrices=100,\n",
    "                    seed=42):\n",
    "    total_losses = {}\n",
    "    for rank in ranks:\n",
    "        print(f'Rank: {rank}')\n",
    "        wmatrix_batch = gen_wishart_batch(2**dim, rank, num_matrices, seed)\n",
    "    \n",
    "        final_losses_classic = []\n",
    "        final_losses_fourier = [[] for _ in range(len(schedules))]\n",
    "    \n",
    "        for i in tqdm(range(num_matrices)):\n",
    "            wmatrix = wmatrix_batch[i]\n",
    "    \n",
    "            # Classic Loss\n",
    "            classic_loss_fn = jit(gen_loss(dim, wmatrix))\n",
    "            opt = optax.adam(learning_rate)\n",
    "            solver = jaxopt.OptaxSolver(fun=classic_loss_fn, opt=opt, maxiter=num_iterations, jit=True)\n",
    "            results = vmap(lambda params: solver.run(params).state.value)(x)\n",
    "            final_losses_classic.append(results)\n",
    "    \n",
    "            # Noisy Loss\n",
    "            noisy_loss_fn = lambda mu, params: gen_noisy_loss(dim, wmatrix)(params, mu)\n",
    "            k_est = estimated_order(noisy_loss_fn, num_parameters=dim, mu=0.5)\n",
    "            nloss = jit(lambda mu, params: noisy_loss_fn(mu, params) / ((1-mu)**k_est + 1e-6))\n",
    "            for j, mu_schedule in enumerate(schedules):\n",
    "                final_params_fourier = batch_optimize_with_adam(nloss,\n",
    "                                                                mu_schedule,\n",
    "                                                                x,\n",
    "                                                                num_iterations,\n",
    "                                                                learning_rate)\n",
    "                final_losses_fourier[j].append(vmap(partial(noisy_loss_fn, 0))(final_params_fourier))\n",
    "        \n",
    "        d = {'classic': np.array(final_losses_classic)}\n",
    "        for j in range(len(schedules)):\n",
    "            d[f'fourier_{j}'] = np.array(final_losses_fourier[j])\n",
    "        total_losses[rank] = d\n",
    "    return total_losses\n",
    "\n",
    "\n",
    "def compute_metrics(total_losses):\n",
    "    total_results = {}\n",
    "    reshape_parameter = 10\n",
    "    for rank in total_losses:\n",
    "        res = {'classic': np.zeros((reshape_parameter, 5))}\n",
    "        for j in range(len(schedules)):\n",
    "            res[f'fourier_{j}'] = np.zeros((reshape_parameter, 5))\n",
    "        for i in range(reshape_parameter):\n",
    "            losses_classic = np.round(total_losses[rank]['classic'].reshape(reshape_parameter,-1)[i], 2)\n",
    "            losses_fourier = [np.round(total_losses[rank][f'fourier_{j}'].reshape(reshape_parameter,-1)[i], 2) for j in range(len(schedules))]\n",
    "            for j in range(len(schedules)):\n",
    "                bin_edges = np.histogram_bin_edges([losses_classic, losses_fourier[j]], bins=50)\n",
    "                bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "                \n",
    "                classic_heights, _ = np.histogram(losses_classic, bins=bin_edges)\n",
    "                fourier_heights, _ = np.histogram(losses_fourier[j], bins=bin_edges)\n",
    "                \n",
    "                # 1. Weighted mean\n",
    "                classic_weighted_mean = np.sum(bin_centers * classic_heights) / np.sum(classic_heights)\n",
    "                fourier_weighted_mean = np.sum(bin_centers * fourier_heights) / np.sum(fourier_heights)\n",
    "        \n",
    "                best_sol = np.percentile(losses_classic, 0.1)\n",
    "        \n",
    "                # 2. Top 5%\n",
    "                threshold = np.percentile(losses_classic, 5)\n",
    "                classic_left_mass_ratio_5 = np.sum(classic_heights[bin_centers <= threshold]) / np.sum(classic_heights)\n",
    "                fourier_left_mass_ratio_5 = np.sum(fourier_heights[bin_centers <= threshold]) / np.sum(fourier_heights)\n",
    "                \n",
    "                # 3. Top 1\n",
    "                classic_prob_best_sol = np.sum(losses_classic <= best_sol) / losses_classic.shape[0]\n",
    "                fourier_prob_best_sol = np.sum(losses_fourier[j] <= best_sol) / losses_fourier[j].shape[0]\n",
    "                \n",
    "                res[f'fourier_{j}'][i] += np.array([fourier_prob_best_sol,\n",
    "                                                    fourier_weighted_mean,\n",
    "                                                    fourier_left_mass_ratio_5])\n",
    "                \n",
    "            res['classic'][i] += np.array([classic_prob_best_sol,\n",
    "                                           classic_weighted_mean,\n",
    "                                           classic_left_mass_ratio_5])\n",
    "        total_results[rank] = res\n",
    "    return total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a932b7-4f99-405d-93ee-53785bcaecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 8\n",
    "ranks = [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250]\n",
    "\n",
    "num_samples = 2000\n",
    "rng = np.random.default_rng(11)\n",
    "x0 = 2 * np.pi * rng.uniform(size=(num_samples, dim))\n",
    "\n",
    "mu_schedule = tanh_schedule(strength=5, max_mu=0.4, t_stop=0.75)\n",
    "schedules = [mu_schedule]\n",
    "\n",
    "total_losses = run_experiments(dim=dim,\n",
    "                               ranks=ranks,\n",
    "                               schedules=schedules,\n",
    "                               x=x0)\n",
    "total_results = compute_metrics(total_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
